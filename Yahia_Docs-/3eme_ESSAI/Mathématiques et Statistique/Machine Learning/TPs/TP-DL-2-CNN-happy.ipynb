{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuU-RPhvflcW"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import h5py\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.models import Sequential\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7gBX7YfTRL"
      },
      "source": [
        "def load_dataset(path_to_train, path_to_test):\n",
        "    train_dataset = h5py.File(path_to_train)\n",
        "    train_x = np.array(train_dataset['train_set_x'][:])\n",
        "    train_y = np.array(train_dataset['train_set_y'][:])\n",
        "\n",
        "    test_dataset = h5py.File(path_to_test)\n",
        "    test_x = np.array(test_dataset['test_set_x'][:])\n",
        "    test_y = np.array(test_dataset['test_set_y'][:])\n",
        "\n",
        "\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF7js4UdhO0F"
      },
      "source": [
        "![Texte alternatifâ€¦](https://raw.githubusercontent.com/Kulbear/deep-learning-coursera/master/Convolutional%20Neural%20Networks/images/house-members.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Load Dataset and normalize image vectors"
      ],
      "metadata": {
        "id": "b2rJyahUe1ft"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOZo0cNbg8ts"
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset(\"train_happy.h5\",\"test_happy.h5\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Sample a random image and print it"
      ],
      "metadata": {
        "id": "RIxmvgZrgtGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Build the model and fit it"
      ],
      "metadata": {
        "id": "nkSGUejZfGwY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJJpc1lppa_m"
      },
      "source": [
        "_________________________________________________________________\n",
        "\n",
        "conv2d_3 (Conv2D)            (None, 64, 64, 32)        4736      \n",
        "_________________________________________________________________\n",
        "batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
        "_________________________________________________________________\n",
        "flatten_2 (Flatten)          (None, 32768)             0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 1)                 32769     \n",
        "_________________________________________________________________\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Evaluate the model"
      ],
      "metadata": {
        "id": "J8c8a111fjio"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFC1nz5_p33b"
      },
      "source": [
        "5) Give the Confusion Matrix and the classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQKL1aDLqjqU"
      },
      "source": [
        "6) Note\n",
        "\n",
        "\n",
        "* Use different regularizataion techniques\n",
        "\n",
        "---\n",
        "* Compare different optimizers\n",
        "\n",
        "---\n",
        "\n",
        "* Display images with Predicted & expected labels (Happy-sad)\n"
      ]
    }
  ]
}