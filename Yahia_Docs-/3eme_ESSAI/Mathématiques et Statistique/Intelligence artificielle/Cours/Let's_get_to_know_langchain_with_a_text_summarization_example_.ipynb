{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e4006577",
      "metadata": {
        "id": "e4006577"
      },
      "source": [
        "# **Complément de cours:**\n",
        "\n",
        "# Exploring LangChain with Scientific Aricle Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825d4caf",
      "metadata": {
        "id": "825d4caf"
      },
      "source": [
        "## I. Brief Explanation of Each Library:\n",
        "\n",
        "- **LangChain** (`langchain`): A framework designed for developing applications that use language models (like GPT). It enables tasks such as document retrieval, question answering, and agent-based interactions.\n",
        "\n",
        "- **Unstructured** (`unstructured`): A library that helps process unstructured data (like text, PDFs, etc.) by extracting and converting it into structured formats for further analysis.\n",
        "\n",
        "- **OpenAI** (`openai`): The official Python client for OpenAI's API, allowing interaction with models like GPT-3 or GPT-4 for tasks like text generation, summarization, and conversation.\n",
        "\n",
        "- **ChromaDB** (`chromadb`): A database focused on vector embeddings, typically used in machine learning for efficient similarity searches, making it useful for handling high-dimensional data like text embeddings.\n",
        "\n",
        "- **Cython** (`Cython`): A library that allows for writing C extensions for Python, helping improve the performance of Python code by compiling it into C.\n",
        "\n",
        "- **Tiktoken** (`tiktoken`): A tokenizer used for OpenAI models, crucial for managing input length by splitting text into tokens, which are used to interact efficiently with language models.\n",
        "\n",
        "Each of these libraries is key in building and optimizing AI applications.\n",
        "\n",
        "---\n",
        "\n",
        "## When Do We Use LangChain?\n",
        "\n",
        "LangChain is used when building applications that involve large language models (LLMs) and require complex workflows or integrations with external systems. You would typically use LangChain in the following scenarios:\n",
        "\n",
        "- **Document Retrieval and QA Systems**: When you want to build applications that can search large document databases and answer questions based on retrieved information, LangChain helps combine retrieval and generation tasks.\n",
        "\n",
        "- **Multi-step AI Agents**: LangChain enables the creation of agents that can perform a series of tasks using LLMs, such as reasoning, planning, and decision-making.\n",
        "\n",
        "- **Customizable Chatbots**: If you need a chatbot with advanced features like memory (context retention over multiple interactions) or integrations with APIs (for pulling live data), LangChain provides an infrastructure for that.\n",
        "\n",
        "- **Tool-augmented LLMs**: When you need an LLM to use external tools like calculators, databases, or APIs in response to user queries, LangChain can coordinate the model's interaction with these tools.\n",
        "\n",
        "- **Workflow Automation**: LangChain is useful for orchestrating complex workflows where LLMs interact with multiple systems, such as combining web scraping, summarization, and database storage in a pipeline.\n",
        "\n",
        "LangChain simplifies and scales the development of LLM-driven applications.\n",
        "\n",
        "---\n",
        "\n",
        "## LangChain for Complex Tasks\n",
        "\n",
        "LangChain is designed to handle **complex workflows** where multiple tasks need to be integrated into a single program. It simplifies the process of combining different components—like language model outputs, data retrieval, and tool usage—into one cohesive application.\n",
        "\n",
        "For example, if you want to:\n",
        "- Retrieve data from a database.\n",
        "- Use an LLM to analyze or summarize that data.\n",
        "- Interact with an external API.\n",
        "- Store results in a different system.\n",
        "\n",
        "LangChain provides the framework to tie all of these steps together seamlessly, allowing for complex task orchestration, while letting the LLM guide the process at each stage. It enables you to build intelligent applications that involve more than just text generation, making it ideal for tasks that require **multi-step reasoning**, interaction with external systems, or **dynamic behavior**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbb7819",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dbb7819",
        "outputId": "ff2a0e39-caff-4133-9ccb-7c500913a1d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (0.1.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (1.4.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (0.0.27)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (0.1.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (1.24.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (1.10.8)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.5.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.15.13-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: chardet in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: requests in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (4.12.2)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (0.6.4)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
            "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
            "     ------------------------------ ------- 786.4/981.5 kB 2.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- 981.5/981.5 kB 2.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: numpy<2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (1.24.3)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (4.9.0)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wrapt in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: tqdm in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (4.65.0)\n",
            "Requirement already satisfied: psutil in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured) (5.9.0)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from beautifulsoup4->unstructured) (2.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from dataclasses-json->unstructured) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from nltk->unstructured) (8.0.4)\n",
            "Requirement already satisfied: joblib in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from nltk->unstructured) (2022.7.9)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests->unstructured) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests->unstructured) (2023.7.22)\n",
            "Requirement already satisfied: colorama in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->unstructured)\n",
            "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured-client->unstructured) (41.0.3)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
            "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting httpx>=0.27.0 (from unstructured-client->unstructured)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Collecting nest-asyncio>=1.6.0 (from unstructured-client->unstructured)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured-client->unstructured) (23.2)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->unstructured)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.15.1)\n",
            "Collecting orderly-set==5.2.2 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
            "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.5.0)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->unstructured-client->unstructured)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.2.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: pycparser in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
            "Downloading unstructured-0.15.13-py3-none-any.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
            "   -------------- ------------------------- 0.8/2.1 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.3/2.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.6/2.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.1/2.1 MB 2.3 MB/s eta 0:00:00\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "   ---------------------------------------- 0.0/586.9 kB ? eta -:--:--\n",
            "   ----------------- ---------------------- 262.1/586.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 586.9/586.9 kB 2.3 MB/s eta 0:00:00\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.10.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
            "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
            "   ------------------- -------------------- 0.8/1.6 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.3/1.6 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.6/1.6 MB 2.3 MB/s eta 0:00:00\n",
            "Downloading unstructured_client-0.25.9-py3-none-any.whl (45 kB)\n",
            "Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
            "Downloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
            "Downloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py): started\n",
            "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=38ac84112e4022bcb7117310d4cf07f07279688801e9d51c99a3c843811fa054\n",
            "  Stored in directory: c:\\users\\21694\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, urllib3, rapidfuzz, python-magic, python-iso639, pypdf, orderly-set, olefile, nest-asyncio, langdetect, jsonpath-python, h11, emoji, charset-normalizer, backoff, python-oxmsg, httpcore, deepdiff, httpx, unstructured-client, unstructured\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.16\n",
            "    Uninstalling urllib3-1.26.16:\n",
            "      Successfully uninstalled urllib3-1.26.16\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.6\n",
            "    Uninstalling nest-asyncio-1.5.6:\n",
            "      Successfully uninstalled nest-asyncio-1.5.6\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.4\n",
            "    Uninstalling charset-normalizer-2.0.4:\n",
            "      Successfully uninstalled charset-normalizer-2.0.4\n",
            "Successfully installed backoff-2.2.1 charset-normalizer-3.3.2 deepdiff-8.0.1 emoji-2.14.0 filetype-1.2.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpath-python-1.0.6 langdetect-1.0.9 nest-asyncio-1.6.0 olefile-0.47 orderly-set-5.2.2 pypdf-5.0.1 python-iso639-2024.4.27 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.0 unstructured-0.15.13 unstructured-client-0.25.9 urllib3-2.2.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "botocore 1.29.76 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from openai) (3.5.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from openai) (0.27.2)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp311-none-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from openai) (1.10.8)\n",
            "Requirement already satisfied: sniffio in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from openai) (1.2.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from openai) (4.65.0)\n",
            "Collecting typing-extensions<5,>=4.11 (from openai)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: certifi in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: colorama in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading jiter-0.5.0-cp311-none-win_amd64.whl (191 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, jiter, distro, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "Successfully installed distro-1.9.0 jiter-0.5.0 openai-1.51.0 typing-extensions-4.12.2\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (1.10.8)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (1.24.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.19.2-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (0.13.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb)\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (6.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from chromadb) (13.8.1)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.5.0)\n",
            "Requirement already satisfied: certifi in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
            "Requirement already satisfied: sniffio in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.2.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
            "Requirement already satisfied: requests in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.31.0)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: sympy in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
            "Downloading chromadb-0.5.11-py3-none-any.whl (603 kB)\n",
            "   ---------------------------------------- 0.0/604.0 kB ? eta -:--:--\n",
            "   ----------------- ---------------------- 262.1/604.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 604.0/604.0 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
            "Downloading bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
            "Downloading build-1.2.2-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl (4.3 MB)\n",
            "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.3/4.3 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 0.8/4.3 MB 2.2 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 1.3/4.3 MB 2.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 1.6/4.3 MB 2.2 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 2.1/4.3 MB 2.1 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 2.6/4.3 MB 2.1 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 2.9/4.3 MB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 3.4/4.3 MB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 3.9/4.3 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.3/4.3 MB 2.1 MB/s eta 0:00:00\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
            "   ---------------- ----------------------- 0.8/1.9 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.3/1.9 MB 2.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.6/1.9 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 2.1 MB/s eta 0:00:00\n",
            "Downloading mmh3-5.0.1-cp311-cp311-win_amd64.whl (39 kB)\n",
            "Downloading onnxruntime-1.19.2-cp311-cp311-win_amd64.whl (11.1 MB)\n",
            "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.8/11.1 MB 2.1 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 1.3/11.1 MB 2.2 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 1.8/11.1 MB 2.2 MB/s eta 0:00:05\n",
            "   -------- ------------------------------- 2.4/11.1 MB 2.3 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 2.6/11.1 MB 2.3 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 3.1/11.1 MB 2.3 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 3.7/11.1 MB 2.3 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 4.2/11.1 MB 2.3 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 4.7/11.1 MB 2.3 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 5.2/11.1 MB 2.3 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 5.8/11.1 MB 2.3 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 6.0/11.1 MB 2.3 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 6.6/11.1 MB 2.2 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 6.8/11.1 MB 2.2 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 7.3/11.1 MB 2.2 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.6/11.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 7.9/11.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 8.1/11.1 MB 2.1 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 8.7/11.1 MB 2.1 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.2/11.1 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 9.4/11.1 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 9.7/11.1 MB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.2/11.1 MB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.5/11.1 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.1 MB 2.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.1/11.1 MB 2.0 MB/s eta 0:00:00\n",
            "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
            "Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "Downloading watchfiles-0.24.0-cp311-none-win_amd64.whl (277 kB)\n",
            "Downloading websockets-13.1-cp311-cp311-win_amd64.whl (159 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml): started\n",
            "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53834 sha256=9ecfacfefe8e4aea04d1e86e823a53ef053a8eccda70a361383780920deac884\n",
            "  Stored in directory: c:\\users\\21694\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, websockets, tenacity, rsa, pyreadline3, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, importlib-resources, httptools, grpcio, chroma-hnswlib, cachetools, bcrypt, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, humanfriendly, googleapis-common-protos, google-auth, build, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation-asgi, onnxruntime, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.2.2\n",
            "    Uninstalling tenacity-8.2.2:\n",
            "      Successfully uninstalled tenacity-8.2.2\n",
            "  Attempting uninstall: bcrypt\n",
            "    Found existing installation: bcrypt 3.2.0\n",
            "    Uninstalling bcrypt-3.2.0:\n",
            "      Successfully uninstalled bcrypt-3.2.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.2.0 build-1.2.2 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.11 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.0 flatbuffers-24.3.25 google-auth-2.35.0 googleapis-common-protos-1.65.0 grpcio-1.66.2 httptools-0.6.1 humanfriendly-10.0 importlib-resources-6.4.5 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.7.0 protobuf-4.25.5 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rsa-4.9 starlette-0.38.6 tenacity-9.0.0 uvicorn-0.31.0 watchfiles-0.24.0 websockets-13.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.1.11 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
            "langchain-community 0.0.27 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
            "langchain-core 0.1.30 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (3.0.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nouveau dossier\\nouveau dossier\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
            "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
            "   ----------- ---------------------------- 262.1/884.5 kB ? eta -:--:--\n",
            "   ----------------------- ---------------- 524.3/884.5 kB 1.0 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 786.4/884.5 kB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 884.5/884.5 kB 1.1 MB/s eta 0:00:00\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~yarrow (C:\\Nouveau dossier\\Nouveau dossier\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fbaaa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08fbaaa5",
        "outputId": "8c42a8b3-a846-463d-c684-c1afb3cbddf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a909899",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a909899",
        "outputId": "0775cacb-6fbd-4c3c-b4d8-3b66a5785e92",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "345a8bb5",
      "metadata": {
        "id": "345a8bb5"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a023db47",
      "metadata": {
        "id": "a023db47"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0666f8e",
      "metadata": {
        "id": "f0666f8e"
      },
      "outputs": [],
      "source": [
        "# Get your API keys from openai, you will need to create an account.\n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ['sk-HmyX9Ii1fiTeXQk34mC3BlbkFJaiPATEj7NSyTFIPi2qrH'] = 'sk-HmyX9Ii1fiTeXQk34mC3BlbkFJaiPATEj7NSyTFIPi2qrH'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0932fa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "6f92efdbb84940a8b935f99c75d39c4e",
            "ac4aa45cba1f491daadf05a1deda3ad0",
            "5655b374c4e24de88a08eba2f899ec2e",
            "97ecaeb3eee74918bbfd10f9943b3ba1",
            "db639866921f46a5b599138ff24a37c4",
            "d1d12bcf7baf44889605c8407647c90f",
            "236af373ebfa415fbfd9935b318092a5",
            "e6719011c4ea47cfb4f0b66c8e799750",
            "5a66a4c6b35044b4a137bb2b6ccb390c",
            "610959c1b4a94bbf8d9f14a7801cd168",
            "bd575e1a3d13405499630995308574cc",
            "ec64db2cd3cd4d73bd7fb2abff0b5ce0",
            "5a9ea071e1984b819422fa263f6adc36",
            "1d443e6bd17041c9ae707dbb62bdabd1",
            "7b3b95c3d1484138a313c29dd1ee32a0",
            "a9bc989e488b44e297e7860db0cd8ea1",
            "04e526a88ee7416093aadd1f25a7cf2d",
            "854fb2ac567f466cb421c3a32d741ca8",
            "4342c319bd4c4687819e0db601333f1b",
            "2de3d73ff1714107bda37e6b0acc67dd",
            "c97857f4ca49467f8c2c079e1ac82ef3",
            "0d21f42330b340b1ba92716d9272415f",
            "376b640b8f1d466288296262a08524c2",
            "5d4ea4ab5f314d1dac9e4f9e7ca91376",
            "5e80cb83c09c48e6b43488bc818b5662",
            "6ec6b65267b04ceda2745d7afd6bc20e",
            "f24fad9a92024aaa88e48f4faeb67524",
            "d9a01d94a7204c99b11a342389c5cc18",
            "169c87ed38694c39847419c13915d0a9",
            "91f5654279084fedbb4a2d97284ac2e1",
            "5f346bc239764f998102d5d5aa180b87",
            "b944306375f943879779ed2031e0658b",
            "bb905bf7a2e74fee9bf520613e954ab8",
            "b6b808bd4270469f9c099a4601795e95",
            "d78983ec25ee45b3a45f2e84031e71d2",
            "b8c663748ad44b0fac764b4f9ae77a74",
            "de157b5854044a8580735f76ac5a52ca",
            "418ea49d652d46a8be99cd16f4de2839",
            "0ef7f7dc08564323bcd6e169e44a6c45",
            "e6a0f304ba574288842c86cad5424c40",
            "eb37192f11b04315988478bffd4f4880",
            "0b31bdeb55bf4224b128d30b64501e87",
            "90368e8c371f4074becc50013e3f3d81",
            "354f093b848d43519fc00ec7ff193988",
            "38f3e7338dda4b17bd8ab73399787f7d",
            "b69a31933d6d4328ba6adabf0d0b76c1",
            "52db42ff7194497a9cccc51441f7c4f6",
            "8c0dca5826e347e5955399161ffca3bd",
            "b0c551bb0b2c4ee296507cc7fa847f51",
            "072ce771213741c092f044b858c06d8e",
            "bcf553014ee34e52b444c1aac4fce056",
            "55508e82fc40460799bd51b97bc87047",
            "81a29df820524a74ba5bf1d2fdcf29b0",
            "4cfcbf287df94a52a752e88c36774183",
            "a21f2fc4b8ce40a2a40093dfeacc88f5"
          ]
        },
        "id": "f0932fa4",
        "outputId": "322f236b-82c5-4ebb-be59-e2ea2c9d00c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f92efdbb84940a8b935f99c75d39c4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec64db2cd3cd4d73bd7fb2abff0b5ce0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "376b640b8f1d466288296262a08524c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6b808bd4270469f9c099a4601795e95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38f3e7338dda4b17bd8ab73399787f7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from transformers import pipeline\n",
        "import PyPDF2\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"sk-HmyX9Ii1fiTeXQk34mC3BlbkFJaiPATEj7NSyTFIPi2qrH\"\n",
        "\n",
        "# Load the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary for a PDF\n",
        "def generate_summary(pdf_path, chunk_size=1000, max_length=50, min_length=10):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_text = \"\"\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            pdf_text += page.extract_text()\n",
        "\n",
        "        # Split text into chunks\n",
        "        chunks = [pdf_text[i:i + chunk_size] for i in range(0, len(pdf_text), chunk_size)]\n",
        "\n",
        "        # Generate summaries for each chunk\n",
        "        summaries = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "            summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "        return \"\\n\".join(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6588ae",
      "metadata": {
        "id": "ef6588ae"
      },
      "outputs": [],
      "source": [
        "# we can use this chunk if we have multiple PDFs\n",
        "# if __name__ == '__main__':\n",
        "#     pdf_dir = '/content/drive/MyDrive/MangrovePDFs'\n",
        "\n",
        "#     for filename in os.listdir(pdf_dir):\n",
        "#         if filename.lower().endswith('.pdf'):\n",
        "#             pdf_path = os.path.join(pdf_dir, filename)\n",
        "#             pdf_summary = generate_summary(pdf_path)\n",
        "\n",
        "#             print(f\"PDF: {filename}\\nSummary:\\n{pdf_summary}\\n{'=' * 30}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa8e8f25",
      "metadata": {
        "id": "fa8e8f25"
      },
      "outputs": [],
      "source": [
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d326093f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d326093f",
        "outputId": "f245bd81-2697-4465-db96-00ebdb622c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF: Change-and-fragmentation-trend-373ec694-c9f4-4e7a-a647-0864880525a4.pdf\n",
            "Summary:\n",
            " The Marshall –Olkin generalized defective Gompertz distribution for surviving fraction modeling, Communications in Statistics - Simulation and Computation .\n",
            " In this article, we introduce a three-level generalization of the Gompertz distribution for cure rate modeling . The main advantage of this new distribution is that it has anincreasing, decreasing, constant, and bathtub-shaped\n",
            " According to the World HealthOrganization, 50% of patients diagnosed with cancer survive the disease . The increase in the like-lihood of survival is due to the positive effect of effective treatments and the major function of the immune system .\n",
            " A general class of non-linear transformation models has been introduced by Tsodikov, Ibrahim, and Yakovlev . The survival function in this class is assumed to be given by gðSðtÞÞ,\n",
            " A non-linear transformation cure rate model was proposed by Balakrishnan and.Milienos . The advantage of defective distributions is threefold: Using a defective model, it is possible to estimate a cure rate with thin½\n",
            " The concept of defective distribution was used by a limited number of authors . There is no need to add an extra parameter such as kin the mixture model which would add complexity to the distribution, especially when the distribution is already complicated .\n",
            " The existence of a variety of defective distributions enables a more adequate description of natural p. well-established distributions . Cantor and Shuster ( 1992), as an example, esti-ishlymated the cure rate from the defective Gom\n",
            " We propose a new defective model called the MO-GDGD . The model is called the Marshall –Olkin generalized defective Gompertz distribution . The survival function of Tis given by: survival function .\n",
            " Marshall –Olkin generalization is shown to be geometric extreme stable . This family of distributions was used in the literature for several models, to name a few: Weibull (Ghitany, Al-Hussaini,\n",
            " The MO-GDGD is based on the law of mortality, Benjamin Gompertz published one of the well-estabred distributions . We propose a new three-level generalization of the distribution . The first level is by\n",
            " The Generalized Modified Gompertz Distribution (MGGD) was then proposed by Martinez and Achcar ( 2017) and by Borges (2017) Their contribution is a modification of the domain of the scale parameter bof the\n",
            " This contribution solves a number of limitations found in the literature and suggests a new three-level generalization of Gompertz distribution . Each level presents a solution to, at least, one of these limitations: Exponentiation level,\n",
            " The survival function is no longer zero when ttends to infinity, it converges instead to the cure rate fraction hin½0, 1/C138: The proposed modification consists in widening the domain of the scale parameter bto\n",
            " Figure 1 plots various scenarios of the probability density function . The new lifetime model is then:                SMOt;r,a,b,c ðÞ ¼r1/C01/C0eabe/\n",
            " The survival function of the Marshall –Olkin extension of D is given by SMOðtÞ . The cure fraction is given in (4) by unsophisti-ishlycated manipulation of inequalities and considering that 0\n",
            " The fail-ure rate of the MO-GDGD can be increasing, decreasing, bathtub, parabolic, or constant depending on the shape parameters . Figure 4 shows the effect of the Marshall –Olkin tilt parameter on the hazard\n",
            " The proposed model generates, inter alia, another defective model as a special case . This model is a two-level generalization of Gompertz distribution . In this special case, the Marshall –Olkin extension is not applied\n",
            " Figure 4: Effect of the Marshall –Olkin tilt parameter on the failure rate curve . Table 1: Special cases of the MO-GDGD.\n",
            " By differentiating the log-likelihood function (8) with respect to r,a,b, and c then setting the resulting equations to zero, we obtain a system of four non-linear equations with four unknownparameters .\n",
            " The two-sided confidence bounds of (1 /C0d)o f r,a,b, and care calculated as follows:. (1/C0b)of r, a, b, c, c\n",
            " The inversion method is applied to generate random samples from the MO-GDGD distribu-portion using Eq. (10) that describes the quantile function . Different sample sizes are used with different choices of parameter values .\n",
            " Theoretical results are illus-trated using medical lifetime data of patients suffering from bladder cancer . In Table 3, we choose a negative value of b to indicate the absence of a cured proportion. In Tables 2 and4,\n",
            " MSE and bias for b<0 and r¼1. sponding MSE . Bias for b <0, r=1.5 and r = 1.5, 1.6255 .\n",
            " The parametric Likelihood ratio ( CH0test statistics) is applied to test whether the null hypothe-heticalses are rejected in favor of the proposed distribution . From Eq. (2.2), the lo lo the data\n",
            " ng-term survival fraction are estimated by:Table 4. MLE, corresponding MSE and bias for b>0 and r<1.2 .\n",
            " The data set consists of ordered remission durations of 128 bladder cancer patients . Table 6 gives maximum likelihood estimators of the unknown parameters of MO-GDGD as well as some of its special cases and their associated p-values and C\n",
            " The likelihood function values under H0and the information criteria. are displayed in Tables 8 and9 . The goodness-of-fit tests KS and CvM for bladder cancer data. is displayed in tables 8 and 9 . The likelihood\n",
            " The value of the log-likelihood function lunder H0 and the information criteria AIC, BIC, and CAIC for bladder cancer data . The model is based on the data set available in the PRO-ACT data set\n",
            " MLEs of the four unknown parameters of MO-GDGD as well as some of its submodels and their associated p-values and the Likelihood ratio test values for PRO-ACT Trials data are presented in Table 10 . The\n",
            " MO-GDGD is the most efficient model, among those applied here, to fit current data . From the low p-values, it is clear that we reject all the four null-hypotheses in favor of the MO-\n",
            " P-values and the Likelihood ratio test values CH0for ALS data . Table 11. od estimators of the unknown parameters of MO-GDGD and some of its special cases and their.associated p-values .\n",
            " AIC, BIC, CAIC meas-cludesures show that MO-GDGD gives the best fit by far . Then comes MO-GGD that gives very close results in terms of CAIC .\n",
            " The performance of the alternative model MO-GDGD is better than the null models GD, MGD, GGD, and GGD . This is also confirmed by the Goodness-of-fit tests KS and CvM\n",
            " Goodness-of-fit tests for ALS data. log-likelihood function lunder H0 and the information criteria AIC, BIC, and CAIC .\n",
            " Anais da Academia Brasileira de Ci ^encias 85 (1):3 –21. The Marshall –Olkin extended generalized Gompertz distribution .\n",
            " The Marshall –Olkin extended generalized Lindley distribution: Properties and applications . An application to uterine cervical cancer data .\n",
            " The generalized Gompertz distribution is based on type I cen-centricsored samples . The Weibull distribution was extended to censored data .\n",
            " The British Journal of Radiology 32:725 –33. 2017. The defective generalized generalized Gompertz dist. 2017 .\n",
            " A. Rocha, R. Nadarajah, V. Tomazella, and F. Louzada. 2016. A new class of defective models based on the Marshall –Olkin family of distributions for cure rate\n",
            " Tsodikov, A. D., J. G. Ibrahim, and A. Y. Yakovlev. age and stage . Statistics in Medicine 21 (6):895 –920.\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in reader.pages:\n",
        "\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "pdf_paths= ['/content/drive/MyDrive/The Marshall Olkin generalized defective Gompertz distribution for surviving fraction modeling.pdf']\n",
        "all_texts = [extract_text_from_pdf(path) for path in pdf_paths]\n",
        "\n",
        "\n",
        "\n",
        "pdf_summary = generate_summary('/content/drive/MyDrive/The Marshall Olkin generalized defective Gompertz distribution for surviving fraction modeling.pdf')\n",
        "\n",
        "print(f\"PDF: {filename}\\nSummary:\\n{pdf_summary}\\n{'=' * 30}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6725f81e",
      "metadata": {
        "id": "6725f81e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}